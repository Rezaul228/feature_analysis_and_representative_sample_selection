{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "from scipy.stats import skew, boxcox\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.plotly as py\n",
    "#py.sign_in('rezaul_abedin', 'Abedin228')\n",
    "#import plotly.graph_objs as go\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "#from sklearn.grid_search import GridSearchCV, RandomizedSearchCV \n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "import time\n",
    "start = time.clock()\n",
    "print('Started!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n",
    "        print(' Time taken: %i minutes and %s seconds.' %\n",
    "              (tmin, round(tsec, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_features():\n",
    "    pkl_file = open('D:/Project/Sample data/train_date_df/train_date_df.pkl', 'rb')\n",
    "    traindata = pickle.load(pkl_file)\n",
    "        \n",
    "    return ['Id'] + list(traindata.columns)\n",
    "        \n",
    "usefuldatefeatures = get_date_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'L0_S0_D1',\n",
       " 'L0_S0_D3',\n",
       " 'L0_S0_D5',\n",
       " 'L0_S0_D7',\n",
       " 'L0_S0_D9',\n",
       " 'L0_S0_D11',\n",
       " 'L0_S0_D13',\n",
       " 'L0_S0_D15',\n",
       " 'L0_S0_D17',\n",
       " 'L0_S0_D19',\n",
       " 'L0_S0_D21',\n",
       " 'L0_S0_D23',\n",
       " 'L0_S1_D26',\n",
       " 'L0_S1_D30',\n",
       " 'L0_S2_D34',\n",
       " 'L0_S2_D38',\n",
       " 'L0_S2_D42',\n",
       " 'L0_S2_D46',\n",
       " 'L0_S2_D50',\n",
       " 'L0_S2_D54',\n",
       " 'L0_S2_D58',\n",
       " 'L0_S2_D62',\n",
       " 'L0_S2_D66',\n",
       " 'L0_S3_D70',\n",
       " 'L0_S3_D74',\n",
       " 'L0_S3_D78',\n",
       " 'L0_S3_D82',\n",
       " 'L0_S3_D86',\n",
       " 'L0_S3_D90',\n",
       " 'L0_S3_D94',\n",
       " 'L0_S3_D98',\n",
       " 'L0_S3_D102',\n",
       " 'L0_S4_D106',\n",
       " 'L0_S4_D111',\n",
       " 'L0_S5_D115',\n",
       " 'L0_S5_D117',\n",
       " 'L0_S6_D120',\n",
       " 'L0_S6_D124',\n",
       " 'L0_S6_D127',\n",
       " 'L0_S6_D130',\n",
       " 'L0_S6_D134',\n",
       " 'L0_S7_D137',\n",
       " 'L0_S7_D139',\n",
       " 'L0_S7_D140',\n",
       " 'L0_S7_D141',\n",
       " 'L0_S7_D143',\n",
       " 'L0_S8_D145',\n",
       " 'L0_S8_D147',\n",
       " 'L0_S8_D148',\n",
       " 'L0_S8_D150',\n",
       " 'L0_S9_D152',\n",
       " 'L0_S9_D157',\n",
       " 'L0_S9_D162',\n",
       " 'L0_S9_D167',\n",
       " 'L0_S9_D172',\n",
       " 'L0_S9_D177',\n",
       " 'L0_S9_D182',\n",
       " 'L0_S9_D187',\n",
       " 'L0_S9_D192',\n",
       " 'L0_S9_D197',\n",
       " 'L0_S9_D202',\n",
       " 'L0_S9_D207',\n",
       " 'L0_S9_D212',\n",
       " 'L0_S10_D216',\n",
       " 'L0_S10_D221',\n",
       " 'L0_S10_D226',\n",
       " 'L0_S10_D231',\n",
       " 'L0_S10_D236',\n",
       " 'L0_S10_D241',\n",
       " 'L0_S10_D246',\n",
       " 'L0_S10_D251',\n",
       " 'L0_S10_D256',\n",
       " 'L0_S10_D261',\n",
       " 'L0_S10_D266',\n",
       " 'L0_S10_D271',\n",
       " 'L0_S10_D276',\n",
       " 'L0_S11_D280',\n",
       " 'L0_S11_D284',\n",
       " 'L0_S11_D288',\n",
       " 'L0_S11_D292',\n",
       " 'L0_S11_D296',\n",
       " 'L0_S11_D300',\n",
       " 'L0_S11_D304',\n",
       " 'L0_S11_D308',\n",
       " 'L0_S11_D312',\n",
       " 'L0_S11_D316',\n",
       " 'L0_S11_D320',\n",
       " 'L0_S11_D324',\n",
       " 'L0_S11_D328',\n",
       " 'L0_S12_D331',\n",
       " 'L0_S12_D333',\n",
       " 'L0_S12_D335',\n",
       " 'L0_S12_D337',\n",
       " 'L0_S12_D339',\n",
       " 'L0_S12_D341',\n",
       " 'L0_S12_D343',\n",
       " 'L0_S12_D345',\n",
       " 'L0_S12_D347',\n",
       " 'L0_S12_D349',\n",
       " 'L0_S12_D351',\n",
       " 'L0_S12_D353',\n",
       " 'L0_S13_D355',\n",
       " 'L0_S13_D357',\n",
       " 'L0_S14_D360',\n",
       " 'L0_S14_D364',\n",
       " 'L0_S14_D368',\n",
       " 'L0_S14_D372',\n",
       " 'L0_S14_D376',\n",
       " 'L0_S14_D380',\n",
       " 'L0_S14_D384',\n",
       " 'L0_S14_D388',\n",
       " 'L0_S14_D392',\n",
       " 'L0_S15_D395',\n",
       " 'L0_S15_D398',\n",
       " 'L0_S15_D401',\n",
       " 'L0_S15_D404',\n",
       " 'L0_S15_D407',\n",
       " 'L0_S15_D410',\n",
       " 'L0_S15_D413',\n",
       " 'L0_S15_D416',\n",
       " 'L0_S15_D419',\n",
       " 'L0_S16_D423',\n",
       " 'L0_S16_D428',\n",
       " 'L0_S17_D432',\n",
       " 'L0_S17_D434',\n",
       " 'L0_S18_D437',\n",
       " 'L0_S18_D441',\n",
       " 'L0_S18_D444',\n",
       " 'L0_S18_D447',\n",
       " 'L0_S18_D451',\n",
       " 'L0_S19_D454',\n",
       " 'L0_S19_D456',\n",
       " 'L0_S19_D457',\n",
       " 'L0_S19_D458',\n",
       " 'L0_S19_D460',\n",
       " 'L0_S20_D462',\n",
       " 'L0_S20_D464',\n",
       " 'L0_S20_D465',\n",
       " 'L0_S20_D467',\n",
       " 'L0_S21_D469',\n",
       " 'L0_S21_D474',\n",
       " 'L0_S21_D479',\n",
       " 'L0_S21_D484',\n",
       " 'L0_S21_D489',\n",
       " 'L0_S21_D494',\n",
       " 'L0_S21_D499',\n",
       " 'L0_S21_D504',\n",
       " 'L0_S21_D509',\n",
       " 'L0_S21_D514',\n",
       " 'L0_S21_D519',\n",
       " 'L0_S21_D524',\n",
       " 'L0_S21_D529',\n",
       " 'L0_S21_D534',\n",
       " 'L0_S21_D539',\n",
       " 'L0_S22_D543',\n",
       " 'L0_S22_D548',\n",
       " 'L0_S22_D553',\n",
       " 'L0_S22_D558',\n",
       " 'L0_S22_D563',\n",
       " 'L0_S22_D568',\n",
       " 'L0_S22_D573',\n",
       " 'L0_S22_D578',\n",
       " 'L0_S22_D583',\n",
       " 'L0_S22_D588',\n",
       " 'L0_S22_D593',\n",
       " 'L0_S22_D598',\n",
       " 'L0_S22_D603',\n",
       " 'L0_S22_D608',\n",
       " 'L0_S22_D613',\n",
       " 'L0_S23_D617',\n",
       " 'L0_S23_D621',\n",
       " 'L0_S23_D625',\n",
       " 'L0_S23_D629',\n",
       " 'L0_S23_D633',\n",
       " 'L0_S23_D637',\n",
       " 'L0_S23_D641',\n",
       " 'L0_S23_D645',\n",
       " 'L0_S23_D649',\n",
       " 'L0_S23_D653',\n",
       " 'L0_S23_D657',\n",
       " 'L0_S23_D661',\n",
       " 'L0_S23_D665',\n",
       " 'L0_S23_D669',\n",
       " 'L0_S23_D673',\n",
       " 'L1_S24_D677',\n",
       " 'L1_S24_D681',\n",
       " 'L1_S24_D685',\n",
       " 'L1_S24_D689',\n",
       " 'L1_S24_D693',\n",
       " 'L1_S24_D697',\n",
       " 'L1_S24_D702',\n",
       " 'L1_S24_D707',\n",
       " 'L1_S24_D712',\n",
       " 'L1_S24_D716',\n",
       " 'L1_S24_D721',\n",
       " 'L1_S24_D725',\n",
       " 'L1_S24_D730',\n",
       " 'L1_S24_D735',\n",
       " 'L1_S24_D739',\n",
       " 'L1_S24_D743',\n",
       " 'L1_S24_D748',\n",
       " 'L1_S24_D753',\n",
       " 'L1_S24_D758',\n",
       " 'L1_S24_D763',\n",
       " 'L1_S24_D768',\n",
       " 'L1_S24_D772',\n",
       " 'L1_S24_D777',\n",
       " 'L1_S24_D782',\n",
       " 'L1_S24_D787',\n",
       " 'L1_S24_D792',\n",
       " 'L1_S24_D797',\n",
       " 'L1_S24_D801',\n",
       " 'L1_S24_D804',\n",
       " 'L1_S24_D807',\n",
       " 'L1_S24_D809',\n",
       " 'L1_S24_D811',\n",
       " 'L1_S24_D813',\n",
       " 'L1_S24_D815',\n",
       " 'L1_S24_D818',\n",
       " 'L1_S24_D822',\n",
       " 'L1_S24_D826',\n",
       " 'L1_S24_D831',\n",
       " 'L1_S24_D836',\n",
       " 'L1_S24_D841',\n",
       " 'L1_S24_D846',\n",
       " 'L1_S24_D850',\n",
       " 'L1_S24_D854',\n",
       " 'L1_S24_D859',\n",
       " 'L1_S24_D864',\n",
       " 'L1_S24_D869',\n",
       " 'L1_S24_D874',\n",
       " 'L1_S24_D879',\n",
       " 'L1_S24_D884',\n",
       " 'L1_S24_D889',\n",
       " 'L1_S24_D894',\n",
       " 'L1_S24_D899',\n",
       " 'L1_S24_D904',\n",
       " 'L1_S24_D909',\n",
       " 'L1_S24_D913',\n",
       " 'L1_S24_D917',\n",
       " 'L1_S24_D922',\n",
       " 'L1_S24_D927',\n",
       " 'L1_S24_D932',\n",
       " 'L1_S24_D937',\n",
       " 'L1_S24_D941',\n",
       " 'L1_S24_D945',\n",
       " 'L1_S24_D950',\n",
       " 'L1_S24_D955',\n",
       " 'L1_S24_D960',\n",
       " 'L1_S24_D965',\n",
       " 'L1_S24_D970',\n",
       " 'L1_S24_D975',\n",
       " 'L1_S24_D980',\n",
       " 'L1_S24_D985',\n",
       " 'L1_S24_D990',\n",
       " 'L1_S24_D995',\n",
       " 'L1_S24_D999',\n",
       " 'L1_S24_D1001',\n",
       " 'L1_S24_D1003',\n",
       " 'L1_S24_D1005',\n",
       " 'L1_S24_D1007',\n",
       " 'L1_S24_D1009',\n",
       " 'L1_S24_D1011',\n",
       " 'L1_S24_D1013',\n",
       " 'L1_S24_D1015',\n",
       " 'L1_S24_D1018',\n",
       " 'L1_S24_D1023',\n",
       " 'L1_S24_D1028',\n",
       " 'L1_S24_D1033',\n",
       " 'L1_S24_D1038',\n",
       " 'L1_S24_D1043',\n",
       " 'L1_S24_D1048',\n",
       " 'L1_S24_D1053',\n",
       " 'L1_S24_D1058',\n",
       " 'L1_S24_D1062',\n",
       " 'L1_S24_D1066',\n",
       " 'L1_S24_D1070',\n",
       " 'L1_S24_D1074',\n",
       " 'L1_S24_D1077',\n",
       " 'L1_S24_D1081',\n",
       " 'L1_S24_D1085',\n",
       " 'L1_S24_D1089',\n",
       " 'L1_S24_D1092',\n",
       " 'L1_S24_D1096',\n",
       " 'L1_S24_D1100',\n",
       " 'L1_S24_D1104',\n",
       " 'L1_S24_D1108',\n",
       " 'L1_S24_D1112',\n",
       " 'L1_S24_D1116',\n",
       " 'L1_S24_D1120',\n",
       " 'L1_S24_D1124',\n",
       " 'L1_S24_D1128',\n",
       " 'L1_S24_D1132',\n",
       " 'L1_S24_D1135',\n",
       " 'L1_S24_D1138',\n",
       " 'L1_S24_D1141',\n",
       " 'L1_S24_D1143',\n",
       " 'L1_S24_D1146',\n",
       " 'L1_S24_D1149',\n",
       " 'L1_S24_D1151',\n",
       " 'L1_S24_D1153',\n",
       " 'L1_S24_D1155',\n",
       " 'L1_S24_D1158',\n",
       " 'L1_S24_D1163',\n",
       " 'L1_S24_D1168',\n",
       " 'L1_S24_D1171',\n",
       " 'L1_S24_D1173',\n",
       " 'L1_S24_D1175',\n",
       " 'L1_S24_D1178',\n",
       " 'L1_S24_D1182',\n",
       " 'L1_S24_D1186',\n",
       " 'L1_S24_D1190',\n",
       " 'L1_S24_D1194',\n",
       " 'L1_S24_D1199',\n",
       " 'L1_S24_D1204',\n",
       " 'L1_S24_D1209',\n",
       " 'L1_S24_D1214',\n",
       " 'L1_S24_D1218',\n",
       " 'L1_S24_D1222',\n",
       " 'L1_S24_D1227',\n",
       " 'L1_S24_D1232',\n",
       " 'L1_S24_D1237',\n",
       " 'L1_S24_D1242',\n",
       " 'L1_S24_D1247',\n",
       " 'L1_S24_D1252',\n",
       " 'L1_S24_D1257',\n",
       " 'L1_S24_D1262',\n",
       " 'L1_S24_D1267',\n",
       " 'L1_S24_D1272',\n",
       " 'L1_S24_D1277',\n",
       " 'L1_S24_D1281',\n",
       " 'L1_S24_D1285',\n",
       " 'L1_S24_D1290',\n",
       " 'L1_S24_D1295',\n",
       " 'L1_S24_D1300',\n",
       " 'L1_S24_D1305',\n",
       " 'L1_S24_D1309',\n",
       " 'L1_S24_D1313',\n",
       " 'L1_S24_D1318',\n",
       " 'L1_S24_D1323',\n",
       " 'L1_S24_D1328',\n",
       " 'L1_S24_D1333',\n",
       " 'L1_S24_D1338',\n",
       " 'L1_S24_D1343',\n",
       " 'L1_S24_D1348',\n",
       " 'L1_S24_D1353',\n",
       " 'L1_S24_D1358',\n",
       " 'L1_S24_D1363',\n",
       " 'L1_S24_D1368',\n",
       " 'L1_S24_D1373',\n",
       " 'L1_S24_D1378',\n",
       " 'L1_S24_D1383',\n",
       " 'L1_S24_D1388',\n",
       " 'L1_S24_D1393',\n",
       " 'L1_S24_D1398',\n",
       " 'L1_S24_D1403',\n",
       " 'L1_S24_D1408',\n",
       " 'L1_S24_D1413',\n",
       " 'L1_S24_D1418',\n",
       " 'L1_S24_D1423',\n",
       " 'L1_S24_D1428',\n",
       " 'L1_S24_D1433',\n",
       " 'L1_S24_D1438',\n",
       " 'L1_S24_D1443',\n",
       " 'L1_S24_D1448',\n",
       " 'L1_S24_D1453',\n",
       " 'L1_S24_D1457',\n",
       " 'L1_S24_D1461',\n",
       " 'L1_S24_D1465',\n",
       " 'L1_S24_D1469',\n",
       " 'L1_S24_D1472',\n",
       " 'L1_S24_D1476',\n",
       " 'L1_S24_D1480',\n",
       " 'L1_S24_D1484',\n",
       " 'L1_S24_D1488',\n",
       " 'L1_S24_D1492',\n",
       " 'L1_S24_D1496',\n",
       " 'L1_S24_D1500',\n",
       " 'L1_S24_D1504',\n",
       " 'L1_S24_D1508',\n",
       " 'L1_S24_D1511',\n",
       " 'L1_S24_D1513',\n",
       " 'L1_S24_D1515',\n",
       " 'L1_S24_D1517',\n",
       " 'L1_S24_D1519',\n",
       " 'L1_S24_D1522',\n",
       " 'L1_S24_D1527',\n",
       " 'L1_S24_D1532',\n",
       " 'L1_S24_D1536',\n",
       " 'L1_S24_D1541',\n",
       " 'L1_S24_D1546',\n",
       " 'L1_S24_D1550',\n",
       " 'L1_S24_D1554',\n",
       " 'L1_S24_D1558',\n",
       " 'L1_S24_D1562',\n",
       " 'L1_S24_D1566',\n",
       " 'L1_S24_D1568',\n",
       " 'L1_S24_D1570',\n",
       " 'L1_S24_D1572',\n",
       " 'L1_S24_D1574',\n",
       " 'L1_S24_D1576',\n",
       " 'L1_S24_D1579',\n",
       " 'L1_S24_D1583',\n",
       " 'L1_S24_D1587',\n",
       " 'L1_S24_D1591',\n",
       " 'L1_S24_D1596',\n",
       " 'L1_S24_D1601',\n",
       " 'L1_S24_D1606',\n",
       " 'L1_S24_D1611',\n",
       " 'L1_S24_D1615',\n",
       " 'L1_S24_D1619',\n",
       " 'L1_S24_D1624',\n",
       " 'L1_S24_D1629',\n",
       " 'L1_S24_D1634',\n",
       " 'L1_S24_D1639',\n",
       " 'L1_S24_D1644',\n",
       " 'L1_S24_D1649',\n",
       " 'L1_S24_D1654',\n",
       " 'L1_S24_D1659',\n",
       " 'L1_S24_D1664',\n",
       " 'L1_S24_D1669',\n",
       " 'L1_S24_D1674',\n",
       " 'L1_S24_D1678',\n",
       " 'L1_S24_D1682',\n",
       " 'L1_S24_D1687',\n",
       " 'L1_S24_D1692',\n",
       " 'L1_S24_D1697',\n",
       " 'L1_S24_D1702',\n",
       " 'L1_S24_D1706',\n",
       " 'L1_S24_D1710',\n",
       " 'L1_S24_D1715',\n",
       " 'L1_S24_D1720',\n",
       " 'L1_S24_D1725',\n",
       " 'L1_S24_D1730',\n",
       " 'L1_S24_D1735',\n",
       " 'L1_S24_D1740',\n",
       " 'L1_S24_D1745',\n",
       " 'L1_S24_D1750',\n",
       " 'L1_S24_D1755',\n",
       " 'L1_S24_D1760',\n",
       " 'L1_S24_D1765',\n",
       " 'L1_S24_D1770',\n",
       " 'L1_S24_D1775',\n",
       " 'L1_S24_D1780',\n",
       " 'L1_S24_D1785',\n",
       " 'L1_S24_D1790',\n",
       " 'L1_S24_D1795',\n",
       " 'L1_S24_D1800',\n",
       " 'L1_S24_D1805',\n",
       " 'L1_S24_D1809',\n",
       " 'L1_S24_D1811',\n",
       " 'L1_S24_D1813',\n",
       " 'L1_S24_D1815',\n",
       " 'L1_S24_D1817',\n",
       " 'L1_S24_D1819',\n",
       " 'L1_S24_D1821',\n",
       " 'L1_S24_D1823',\n",
       " 'L1_S24_D1825',\n",
       " 'L1_S24_D1826',\n",
       " 'L1_S24_D1828',\n",
       " 'L1_S24_D1830',\n",
       " 'L1_S24_D1832',\n",
       " 'L1_S24_D1833',\n",
       " 'L1_S24_D1835',\n",
       " 'L1_S24_D1837',\n",
       " 'L1_S24_D1839',\n",
       " 'L1_S24_D1841',\n",
       " 'L1_S24_D1843',\n",
       " 'L1_S24_D1845',\n",
       " 'L1_S24_D1847',\n",
       " 'L1_S24_D1849',\n",
       " 'L1_S24_D1851',\n",
       " 'L1_S25_D1854',\n",
       " 'L1_S25_D1857',\n",
       " 'L1_S25_D1860',\n",
       " 'L1_S25_D1862',\n",
       " 'L1_S25_D1864',\n",
       " 'L1_S25_D1867',\n",
       " 'L1_S25_D1871',\n",
       " 'L1_S25_D1875',\n",
       " 'L1_S25_D1879',\n",
       " 'L1_S25_D1883',\n",
       " 'L1_S25_D1887',\n",
       " 'L1_S25_D1891',\n",
       " 'L1_S25_D1893',\n",
       " 'L1_S25_D1895',\n",
       " 'L1_S25_D1898',\n",
       " 'L1_S25_D1902',\n",
       " 'L1_S25_D1906',\n",
       " 'L1_S25_D1911',\n",
       " 'L1_S25_D1916',\n",
       " 'L1_S25_D1921',\n",
       " 'L1_S25_D1926',\n",
       " 'L1_S25_D1931',\n",
       " 'L1_S25_D1935',\n",
       " 'L1_S25_D1940',\n",
       " 'L1_S25_D1945',\n",
       " 'L1_S25_D1950',\n",
       " 'L1_S25_D1955',\n",
       " 'L1_S25_D1960',\n",
       " 'L1_S25_D1965',\n",
       " 'L1_S25_D1970',\n",
       " 'L1_S25_D1975',\n",
       " 'L1_S25_D1980',\n",
       " 'L1_S25_D1984',\n",
       " 'L1_S25_D1989',\n",
       " 'L1_S25_D1994',\n",
       " 'L1_S25_D1999',\n",
       " 'L1_S25_D2004',\n",
       " 'L1_S25_D2009',\n",
       " 'L1_S25_D2013',\n",
       " 'L1_S25_D2018',\n",
       " 'L1_S25_D2023',\n",
       " 'L1_S25_D2028',\n",
       " 'L1_S25_D2033',\n",
       " 'L1_S25_D2038',\n",
       " 'L1_S25_D2043',\n",
       " 'L1_S25_D2048',\n",
       " 'L1_S25_D2053',\n",
       " 'L1_S25_D2058',\n",
       " 'L1_S25_D2063',\n",
       " 'L1_S25_D2068',\n",
       " 'L1_S25_D2073',\n",
       " 'L1_S25_D2078',\n",
       " 'L1_S25_D2083',\n",
       " 'L1_S25_D2088',\n",
       " 'L1_S25_D2093',\n",
       " 'L1_S25_D2098',\n",
       " 'L1_S25_D2103',\n",
       " 'L1_S25_D2108',\n",
       " 'L1_S25_D2113',\n",
       " 'L1_S25_D2118',\n",
       " 'L1_S25_D2123',\n",
       " 'L1_S25_D2128',\n",
       " 'L1_S25_D2133',\n",
       " 'L1_S25_D2138',\n",
       " 'L1_S25_D2140',\n",
       " 'L1_S25_D2143',\n",
       " 'L1_S25_D2146',\n",
       " 'L1_S25_D2149',\n",
       " 'L1_S25_D2151',\n",
       " 'L1_S25_D2154',\n",
       " 'L1_S25_D2157',\n",
       " 'L1_S25_D2160',\n",
       " 'L1_S25_D2163',\n",
       " 'L1_S25_D2166',\n",
       " 'L1_S25_D2169',\n",
       " 'L1_S25_D2172',\n",
       " 'L1_S25_D2175',\n",
       " 'L1_S25_D2178',\n",
       " 'L1_S25_D2180',\n",
       " 'L1_S25_D2183',\n",
       " 'L1_S25_D2186',\n",
       " 'L1_S25_D2189',\n",
       " 'L1_S25_D2192',\n",
       " 'L1_S25_D2195',\n",
       " 'L1_S25_D2198',\n",
       " 'L1_S25_D2201',\n",
       " 'L1_S25_D2204',\n",
       " 'L1_S25_D2206',\n",
       " 'L1_S25_D2209',\n",
       " 'L1_S25_D2212',\n",
       " 'L1_S25_D2214',\n",
       " 'L1_S25_D2216',\n",
       " 'L1_S25_D2219',\n",
       " 'L1_S25_D2222',\n",
       " 'L1_S25_D2225',\n",
       " 'L1_S25_D2228',\n",
       " 'L1_S25_D2230',\n",
       " 'L1_S25_D2232',\n",
       " 'L1_S25_D2234',\n",
       " 'L1_S25_D2235',\n",
       " 'L1_S25_D2236',\n",
       " 'L1_S25_D2238',\n",
       " 'L1_S25_D2240',\n",
       " 'L1_S25_D2242',\n",
       " 'L1_S25_D2244',\n",
       " 'L1_S25_D2246',\n",
       " 'L1_S25_D2248',\n",
       " 'L1_S25_D2251',\n",
       " 'L1_S25_D2255',\n",
       " 'L1_S25_D2260',\n",
       " 'L1_S25_D2265',\n",
       " 'L1_S25_D2270',\n",
       " 'L1_S25_D2275',\n",
       " 'L1_S25_D2280',\n",
       " 'L1_S25_D2284',\n",
       " 'L1_S25_D2289',\n",
       " 'L1_S25_D2294',\n",
       " 'L1_S25_D2299',\n",
       " 'L1_S25_D2304',\n",
       " 'L1_S25_D2309',\n",
       " 'L1_S25_D2314',\n",
       " 'L1_S25_D2319',\n",
       " 'L1_S25_D2324',\n",
       " 'L1_S25_D2329',\n",
       " 'L1_S25_D2333',\n",
       " 'L1_S25_D2338',\n",
       " 'L1_S25_D2343',\n",
       " 'L1_S25_D2348',\n",
       " 'L1_S25_D2353',\n",
       " 'L1_S25_D2358',\n",
       " 'L1_S25_D2362',\n",
       " 'L1_S25_D2367',\n",
       " 'L1_S25_D2372',\n",
       " 'L1_S25_D2377',\n",
       " 'L1_S25_D2382',\n",
       " 'L1_S25_D2387',\n",
       " 'L1_S25_D2392',\n",
       " 'L1_S25_D2397',\n",
       " 'L1_S25_D2402',\n",
       " 'L1_S25_D2406',\n",
       " 'L1_S25_D2409',\n",
       " 'L1_S25_D2412',\n",
       " 'L1_S25_D2415',\n",
       " 'L1_S25_D2418',\n",
       " 'L1_S25_D2421',\n",
       " 'L1_S25_D2424',\n",
       " 'L1_S25_D2427',\n",
       " 'L1_S25_D2430',\n",
       " 'L1_S25_D2432',\n",
       " 'L1_S25_D2434',\n",
       " 'L1_S25_D2436',\n",
       " 'L1_S25_D2438',\n",
       " 'L1_S25_D2440',\n",
       " 'L1_S25_D2442',\n",
       " 'L1_S25_D2444',\n",
       " 'L1_S25_D2445',\n",
       " 'L1_S25_D2446',\n",
       " 'L1_S25_D2448',\n",
       " 'L1_S25_D2450',\n",
       " 'L1_S25_D2452',\n",
       " 'L1_S25_D2453',\n",
       " 'L1_S25_D2455',\n",
       " 'L1_S25_D2457',\n",
       " 'L1_S25_D2459',\n",
       " 'L1_S25_D2461',\n",
       " 'L1_S25_D2463',\n",
       " 'L1_S25_D2465',\n",
       " 'L1_S25_D2467',\n",
       " 'L1_S25_D2469',\n",
       " 'L1_S25_D2471',\n",
       " 'L1_S25_D2474',\n",
       " 'L1_S25_D2477',\n",
       " 'L1_S25_D2480',\n",
       " 'L1_S25_D2483',\n",
       " 'L1_S25_D2486',\n",
       " 'L1_S25_D2489',\n",
       " 'L1_S25_D2492',\n",
       " 'L1_S25_D2495',\n",
       " 'L1_S25_D2497',\n",
       " 'L1_S25_D2499',\n",
       " 'L1_S25_D2501',\n",
       " 'L1_S25_D2502',\n",
       " 'L1_S25_D2503',\n",
       " 'L1_S25_D2505',\n",
       " 'L1_S25_D2507',\n",
       " 'L1_S25_D2509',\n",
       " 'L1_S25_D2511',\n",
       " 'L1_S25_D2513',\n",
       " 'L1_S25_D2515',\n",
       " 'L1_S25_D2518',\n",
       " 'L1_S25_D2522',\n",
       " 'L1_S25_D2527',\n",
       " 'L1_S25_D2532',\n",
       " 'L1_S25_D2537',\n",
       " 'L1_S25_D2542',\n",
       " 'L1_S25_D2547',\n",
       " 'L1_S25_D2551',\n",
       " 'L1_S25_D2556',\n",
       " 'L1_S25_D2561',\n",
       " 'L1_S25_D2566',\n",
       " 'L1_S25_D2571',\n",
       " 'L1_S25_D2576',\n",
       " 'L1_S25_D2581',\n",
       " 'L1_S25_D2586',\n",
       " 'L1_S25_D2591',\n",
       " 'L1_S25_D2596',\n",
       " 'L1_S25_D2600',\n",
       " 'L1_S25_D2605',\n",
       " 'L1_S25_D2610',\n",
       " 'L1_S25_D2615',\n",
       " 'L1_S25_D2620',\n",
       " 'L1_S25_D2625',\n",
       " 'L1_S25_D2629',\n",
       " 'L1_S25_D2634',\n",
       " 'L1_S25_D2639',\n",
       " 'L1_S25_D2644',\n",
       " 'L1_S25_D2649',\n",
       " 'L1_S25_D2654',\n",
       " 'L1_S25_D2659',\n",
       " 'L1_S25_D2664',\n",
       " 'L1_S25_D2669',\n",
       " 'L1_S25_D2674',\n",
       " 'L1_S25_D2679',\n",
       " 'L1_S25_D2684',\n",
       " 'L1_S25_D2689',\n",
       " 'L1_S25_D2694',\n",
       " 'L1_S25_D2699',\n",
       " 'L1_S25_D2704',\n",
       " 'L1_S25_D2709',\n",
       " 'L1_S25_D2713',\n",
       " 'L1_S25_D2715',\n",
       " 'L1_S25_D2717',\n",
       " 'L1_S25_D2719',\n",
       " 'L1_S25_D2721',\n",
       " 'L1_S25_D2723',\n",
       " 'L1_S25_D2725',\n",
       " 'L1_S25_D2727',\n",
       " 'L1_S25_D2728',\n",
       " 'L1_S25_D2729',\n",
       " 'L1_S25_D2731',\n",
       " 'L1_S25_D2733',\n",
       " 'L1_S25_D2735',\n",
       " 'L1_S25_D2736',\n",
       " 'L1_S25_D2738',\n",
       " 'L1_S25_D2740',\n",
       " 'L1_S25_D2742',\n",
       " 'L1_S25_D2744',\n",
       " 'L1_S25_D2746',\n",
       " 'L1_S25_D2748',\n",
       " 'L1_S25_D2750',\n",
       " 'L1_S25_D2752',\n",
       " 'L1_S25_D2754',\n",
       " 'L1_S25_D2757',\n",
       " 'L1_S25_D2760',\n",
       " 'L1_S25_D2763',\n",
       " 'L1_S25_D2766',\n",
       " 'L1_S25_D2769',\n",
       " 'L1_S25_D2772',\n",
       " 'L1_S25_D2775',\n",
       " 'L1_S25_D2778',\n",
       " 'L1_S25_D2780',\n",
       " 'L1_S25_D2782',\n",
       " 'L1_S25_D2784',\n",
       " 'L1_S25_D2785',\n",
       " 'L1_S25_D2786',\n",
       " 'L1_S25_D2788',\n",
       " 'L1_S25_D2790',\n",
       " 'L1_S25_D2792',\n",
       " 'L1_S25_D2794',\n",
       " 'L1_S25_D2796',\n",
       " 'L1_S25_D2798',\n",
       " 'L1_S25_D2801',\n",
       " 'L1_S25_D2805',\n",
       " 'L1_S25_D2810',\n",
       " 'L1_S25_D2815',\n",
       " 'L1_S25_D2820',\n",
       " 'L1_S25_D2825',\n",
       " 'L1_S25_D2830',\n",
       " 'L1_S25_D2834',\n",
       " 'L1_S25_D2839',\n",
       " 'L1_S25_D2844',\n",
       " 'L1_S25_D2849',\n",
       " 'L1_S25_D2854',\n",
       " 'L1_S25_D2859',\n",
       " 'L1_S25_D2864',\n",
       " 'L1_S25_D2869',\n",
       " 'L1_S25_D2874',\n",
       " 'L1_S25_D2879',\n",
       " 'L1_S25_D2883',\n",
       " 'L1_S25_D2888',\n",
       " 'L1_S25_D2893',\n",
       " 'L1_S25_D2898',\n",
       " 'L1_S25_D2903',\n",
       " 'L1_S25_D2908',\n",
       " 'L1_S25_D2912',\n",
       " 'L1_S25_D2917',\n",
       " 'L1_S25_D2922',\n",
       " 'L1_S25_D2927',\n",
       " 'L1_S25_D2932',\n",
       " 'L1_S25_D2937',\n",
       " 'L1_S25_D2942',\n",
       " 'L1_S25_D2947',\n",
       " 'L1_S25_D2952',\n",
       " 'L1_S25_D2957',\n",
       " 'L1_S25_D2962',\n",
       " 'L1_S25_D2967',\n",
       " 'L1_S25_D2972',\n",
       " 'L1_S25_D2977',\n",
       " 'L1_S25_D2982',\n",
       " 'L1_S25_D2987',\n",
       " 'L1_S25_D2992',\n",
       " 'L1_S25_D2996',\n",
       " 'L1_S25_D2998',\n",
       " 'L1_S25_D3000',\n",
       " 'L1_S25_D3002',\n",
       " 'L1_S25_D3004',\n",
       " 'L1_S25_D3006',\n",
       " 'L1_S25_D3008',\n",
       " 'L1_S25_D3010',\n",
       " 'L1_S25_D3011',\n",
       " 'L1_S25_D3012',\n",
       " 'L1_S25_D3014',\n",
       " 'L1_S25_D3016',\n",
       " 'L1_S25_D3018',\n",
       " 'L1_S25_D3019',\n",
       " 'L1_S25_D3021',\n",
       " 'L1_S25_D3023',\n",
       " 'L1_S25_D3025',\n",
       " 'L1_S25_D3027',\n",
       " 'L1_S25_D3029',\n",
       " 'L1_S25_D3031',\n",
       " 'L1_S25_D3033',\n",
       " 'L1_S25_D3035',\n",
       " 'L2_S26_D3037',\n",
       " 'L2_S26_D3041',\n",
       " 'L2_S26_D3044',\n",
       " 'L2_S26_D3048',\n",
       " 'L2_S26_D3052',\n",
       " 'L2_S26_D3056',\n",
       " 'L2_S26_D3059',\n",
       " 'L2_S26_D3063',\n",
       " 'L2_S26_D3066',\n",
       " 'L2_S26_D3070',\n",
       " 'L2_S26_D3074',\n",
       " 'L2_S26_D3078',\n",
       " 'L2_S26_D3081',\n",
       " 'L2_S26_D3084',\n",
       " 'L2_S26_D3087',\n",
       " 'L2_S26_D3090',\n",
       " 'L2_S26_D3093',\n",
       " 'L2_S26_D3096',\n",
       " 'L2_S26_D3100',\n",
       " 'L2_S26_D3103',\n",
       " 'L2_S26_D3107',\n",
       " 'L2_S26_D3110',\n",
       " 'L2_S26_D3114',\n",
       " 'L2_S26_D3118',\n",
       " 'L2_S26_D3122',\n",
       " 'L2_S26_D3126',\n",
       " 'L2_S27_D3130',\n",
       " 'L2_S27_D3134',\n",
       " 'L2_S27_D3137',\n",
       " 'L2_S27_D3141',\n",
       " 'L2_S27_D3145',\n",
       " 'L2_S27_D3149',\n",
       " 'L2_S27_D3152',\n",
       " 'L2_S27_D3156',\n",
       " 'L2_S27_D3159',\n",
       " 'L2_S27_D3163',\n",
       " 'L2_S27_D3167',\n",
       " 'L2_S27_D3171',\n",
       " 'L2_S27_D3174',\n",
       " 'L2_S27_D3177',\n",
       " 'L2_S27_D3180',\n",
       " 'L2_S27_D3183',\n",
       " 'L2_S27_D3186',\n",
       " 'L2_S27_D3189',\n",
       " 'L2_S27_D3193',\n",
       " 'L2_S27_D3196',\n",
       " 'L2_S27_D3200',\n",
       " 'L2_S27_D3203',\n",
       " 'L2_S27_D3207',\n",
       " 'L2_S27_D3211',\n",
       " 'L2_S27_D3215',\n",
       " 'L2_S27_D3219',\n",
       " 'L2_S28_D3223',\n",
       " 'L2_S28_D3227',\n",
       " 'L2_S28_D3230',\n",
       " 'L2_S28_D3234',\n",
       " 'L2_S28_D3238',\n",
       " 'L2_S28_D3242',\n",
       " 'L2_S28_D3245',\n",
       " 'L2_S28_D3249',\n",
       " 'L2_S28_D3252',\n",
       " 'L2_S28_D3256',\n",
       " 'L2_S28_D3260',\n",
       " 'L2_S28_D3264',\n",
       " 'L2_S28_D3267',\n",
       " 'L2_S28_D3270',\n",
       " 'L2_S28_D3273',\n",
       " 'L2_S28_D3276',\n",
       " 'L2_S28_D3279',\n",
       " 'L2_S28_D3282',\n",
       " 'L2_S28_D3286',\n",
       " 'L2_S28_D3289',\n",
       " 'L2_S28_D3293',\n",
       " 'L2_S28_D3296',\n",
       " 'L2_S28_D3300',\n",
       " 'L2_S28_D3304',\n",
       " 'L2_S28_D3308',\n",
       " 'L2_S28_D3312',\n",
       " 'L3_S29_D3316',\n",
       " 'L3_S29_D3319',\n",
       " 'L3_S29_D3322',\n",
       " 'L3_S29_D3325',\n",
       " 'L3_S29_D3328',\n",
       " 'L3_S29_D3331',\n",
       " 'L3_S29_D3334',\n",
       " 'L3_S29_D3337',\n",
       " 'L3_S29_D3340',\n",
       " 'L3_S29_D3343',\n",
       " 'L3_S29_D3346',\n",
       " 'L3_S29_D3349',\n",
       " 'L3_S29_D3352',\n",
       " 'L3_S29_D3355',\n",
       " 'L3_S29_D3358',\n",
       " 'L3_S29_D3361',\n",
       " 'L3_S29_D3363',\n",
       " 'L3_S29_D3365',\n",
       " 'L3_S29_D3368',\n",
       " 'L3_S29_D3371',\n",
       " 'L3_S29_D3374',\n",
       " 'L3_S29_D3377',\n",
       " 'L3_S29_D3380',\n",
       " 'L3_S29_D3383',\n",
       " 'L3_S29_D3386',\n",
       " 'L3_S29_D3389',\n",
       " 'L3_S29_D3391',\n",
       " 'L3_S29_D3393',\n",
       " 'L3_S29_D3396',\n",
       " 'L3_S29_D3399',\n",
       " 'L3_S29_D3402',\n",
       " 'L3_S29_D3405',\n",
       " 'L3_S29_D3408',\n",
       " 'L3_S29_D3410',\n",
       " 'L3_S29_D3413',\n",
       " 'L3_S29_D3415',\n",
       " 'L3_S29_D3417',\n",
       " 'L3_S29_D3419',\n",
       " 'L3_S29_D3422',\n",
       " 'L3_S29_D3425',\n",
       " 'L3_S29_D3428',\n",
       " 'L3_S29_D3431',\n",
       " 'L3_S29_D3434',\n",
       " 'L3_S29_D3437',\n",
       " 'L3_S29_D3440',\n",
       " 'L3_S29_D3443',\n",
       " 'L3_S29_D3445',\n",
       " 'L3_S29_D3447',\n",
       " 'L3_S29_D3450',\n",
       " 'L3_S29_D3453',\n",
       " 'L3_S29_D3456',\n",
       " 'L3_S29_D3459',\n",
       " 'L3_S29_D3462',\n",
       " 'L3_S29_D3465',\n",
       " 'L3_S29_D3468',\n",
       " 'L3_S29_D3471',\n",
       " 'L3_S29_D3474',\n",
       " 'L3_S29_D3477',\n",
       " 'L3_S29_D3480',\n",
       " 'L3_S29_D3483',\n",
       " 'L3_S29_D3486',\n",
       " 'L3_S29_D3489',\n",
       " 'L3_S29_D3492',\n",
       " 'L3_S30_D3496',\n",
       " 'L3_S30_D3501',\n",
       " 'L3_S30_D3506',\n",
       " 'L3_S30_D3511',\n",
       " 'L3_S30_D3516',\n",
       " 'L3_S30_D3521',\n",
       " 'L3_S30_D3526',\n",
       " 'L3_S30_D3531',\n",
       " 'L3_S30_D3536',\n",
       " 'L3_S30_D3541',\n",
       " 'L3_S30_D3546',\n",
       " 'L3_S30_D3551',\n",
       " 'L3_S30_D3556',\n",
       " 'L3_S30_D3561',\n",
       " 'L3_S30_D3566',\n",
       " 'L3_S30_D3571',\n",
       " 'L3_S30_D3576',\n",
       " 'L3_S30_D3581',\n",
       " 'L3_S30_D3586',\n",
       " 'L3_S30_D3591',\n",
       " 'L3_S30_D3596',\n",
       " 'L3_S30_D3601',\n",
       " 'L3_S30_D3606',\n",
       " 'L3_S30_D3611',\n",
       " 'L3_S30_D3616',\n",
       " 'L3_S30_D3621',\n",
       " 'L3_S30_D3626',\n",
       " 'L3_S30_D3631',\n",
       " 'L3_S30_D3636',\n",
       " 'L3_S30_D3641',\n",
       " 'L3_S30_D3646',\n",
       " 'L3_S30_D3651',\n",
       " 'L3_S30_D3656',\n",
       " 'L3_S30_D3661',\n",
       " 'L3_S30_D3666',\n",
       " 'L3_S30_D3671',\n",
       " 'L3_S30_D3676',\n",
       " 'L3_S30_D3681',\n",
       " 'L3_S30_D3686',\n",
       " 'L3_S30_D3691',\n",
       " 'L3_S30_D3696',\n",
       " 'L3_S30_D3701',\n",
       " 'L3_S30_D3706',\n",
       " 'L3_S30_D3711',\n",
       " 'L3_S30_D3716',\n",
       " 'L3_S30_D3721',\n",
       " 'L3_S30_D3726',\n",
       " 'L3_S30_D3731',\n",
       " 'L3_S30_D3736',\n",
       " 'L3_S30_D3741',\n",
       " 'L3_S30_D3746',\n",
       " 'L3_S30_D3751',\n",
       " 'L3_S30_D3756',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usefuldatefeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date():\n",
    "    ## get the data plus do some feature engineering\n",
    "    trainfile = 'D:/Project/Sample data/Sam_8/train_date.csv'# without mean\n",
    "    testfile = 'D:/Project/Sample data/Sam_test_8/test_date.csv'# without mean\n",
    " \n",
    "    train = pd.read_csv(trainfile, usecols=usefuldatefeatures)\n",
    "    features = list(train.columns)\n",
    "    features.remove('Id')\n",
    "    df_train = train[['Id']].copy()\n",
    "    df_train['mindate'] = train[features].min(axis=1).values\n",
    "    \n",
    "    #print (train[features].min(axis=1).values)\n",
    "    #print (df_train.head())\n",
    "    \n",
    "    df_train['maxdate'] = train[features].max(axis=1).values \n",
    "    #print (df_train.head())\n",
    "    df_train['diff'] = df_train['maxdate'] - df_train['mindate']    \n",
    "    \n",
    "    #print (df_train.head())\n",
    "        \n",
    "    test = pd.read_csv(testfile, usecols=usefuldatefeatures)\n",
    "    df_test = test[['Id']].copy()\n",
    "    df_test['mindate'] = test[features].min(axis=1).values\n",
    "    df_test['maxdate'] = test[features].max(axis=1).values \n",
    "    df_test['diff'] = df_test['maxdate'] - df_test['mindate']\n",
    "        \n",
    "    df = pd.concat([df_train, df_test])     \n",
    "    df.sort_values(by=['mindate', 'Id'], inplace=True)\n",
    "    \n",
    "    #print(df.head())\n",
    "    \n",
    "    df['df_id_diff'] = df.Id.diff()\n",
    "    #print(df.Id.diff())\n",
    "    rew = np.full_like(df.df_id_diff.values, np.nan)\n",
    "    #print(rew)\n",
    "    rew[0:-1] = -df.df_id_diff.values[1:]\n",
    "    #print (df.df_id_diff.values[1:])\n",
    "    df['df_id_diff_reverse'] = rew\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pros = get_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>diff</th>\n",
       "      <th>df_id_diff</th>\n",
       "      <th>df_id_diff_reverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>1060450</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-195631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>1256081</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.39</td>\n",
       "      <td>195631.0</td>\n",
       "      <td>784399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>471682</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-784399.0</td>\n",
       "      <td>377088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>94594</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-377088.0</td>\n",
       "      <td>-381493.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>476087</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.22</td>\n",
       "      <td>381493.0</td>\n",
       "      <td>325086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>151001</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-325086.0</td>\n",
       "      <td>-431925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>582926</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431925.0</td>\n",
       "      <td>-1008321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5350</th>\n",
       "      <td>1591247</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1008321.0</td>\n",
       "      <td>103192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>1488055</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-103192.0</td>\n",
       "      <td>-292243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>1780298</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.44</td>\n",
       "      <td>292243.0</td>\n",
       "      <td>611695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>1168603</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-611695.0</td>\n",
       "      <td>540253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>628350</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.44</td>\n",
       "      <td>-540253.0</td>\n",
       "      <td>-12394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>640744</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.27</td>\n",
       "      <td>12394.0</td>\n",
       "      <td>554192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>86552</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-554192.0</td>\n",
       "      <td>20688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>65864</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-20688.0</td>\n",
       "      <td>-1163392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>1229256</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1163392.0</td>\n",
       "      <td>-208687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>1437943</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.04</td>\n",
       "      <td>208687.0</td>\n",
       "      <td>411090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>1026853</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-411090.0</td>\n",
       "      <td>-21743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3561</th>\n",
       "      <td>1048596</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.02</td>\n",
       "      <td>21743.0</td>\n",
       "      <td>-1083444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>2132040</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1083444.0</td>\n",
       "      <td>417361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>1714679</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-417361.0</td>\n",
       "      <td>769428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>945251</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-769428.0</td>\n",
       "      <td>-156690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>1101941</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.03</td>\n",
       "      <td>156690.0</td>\n",
       "      <td>-229849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>1331790</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.03</td>\n",
       "      <td>229849.0</td>\n",
       "      <td>-552936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>1884726</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.18</td>\n",
       "      <td>552936.0</td>\n",
       "      <td>876444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>1008282</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-876444.0</td>\n",
       "      <td>-709138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>1717420</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.31</td>\n",
       "      <td>709138.0</td>\n",
       "      <td>324426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>1392994</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-324426.0</td>\n",
       "      <td>-213540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>1606534</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.24</td>\n",
       "      <td>213540.0</td>\n",
       "      <td>1116452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>490082</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1116452.0</td>\n",
       "      <td>-1164025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>1663675</td>\n",
       "      <td>1710.17</td>\n",
       "      <td>1713.70</td>\n",
       "      <td>3.53</td>\n",
       "      <td>-589427.0</td>\n",
       "      <td>-101804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>1765479</td>\n",
       "      <td>1710.21</td>\n",
       "      <td>1714.04</td>\n",
       "      <td>3.83</td>\n",
       "      <td>101804.0</td>\n",
       "      <td>987906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>777573</td>\n",
       "      <td>1710.22</td>\n",
       "      <td>1714.01</td>\n",
       "      <td>3.79</td>\n",
       "      <td>-987906.0</td>\n",
       "      <td>-775674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>1553247</td>\n",
       "      <td>1710.27</td>\n",
       "      <td>1713.99</td>\n",
       "      <td>3.72</td>\n",
       "      <td>775674.0</td>\n",
       "      <td>-686964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>2240211</td>\n",
       "      <td>1710.33</td>\n",
       "      <td>1714.18</td>\n",
       "      <td>3.85</td>\n",
       "      <td>686964.0</td>\n",
       "      <td>1577430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>662781</td>\n",
       "      <td>1710.34</td>\n",
       "      <td>1714.18</td>\n",
       "      <td>3.84</td>\n",
       "      <td>-1577430.0</td>\n",
       "      <td>35934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>626847</td>\n",
       "      <td>1710.37</td>\n",
       "      <td>1714.13</td>\n",
       "      <td>3.76</td>\n",
       "      <td>-35934.0</td>\n",
       "      <td>212703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>414144</td>\n",
       "      <td>1710.44</td>\n",
       "      <td>1717.61</td>\n",
       "      <td>7.17</td>\n",
       "      <td>-212703.0</td>\n",
       "      <td>-1549871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>1964015</td>\n",
       "      <td>1710.44</td>\n",
       "      <td>1717.68</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1549871.0</td>\n",
       "      <td>-6853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6639</th>\n",
       "      <td>1970868</td>\n",
       "      <td>1710.48</td>\n",
       "      <td>1714.30</td>\n",
       "      <td>3.82</td>\n",
       "      <td>6853.0</td>\n",
       "      <td>284032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>1686836</td>\n",
       "      <td>1710.50</td>\n",
       "      <td>1715.66</td>\n",
       "      <td>5.16</td>\n",
       "      <td>-284032.0</td>\n",
       "      <td>-157931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>1844767</td>\n",
       "      <td>1710.61</td>\n",
       "      <td>1715.67</td>\n",
       "      <td>5.06</td>\n",
       "      <td>157931.0</td>\n",
       "      <td>1494742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>350025</td>\n",
       "      <td>1710.69</td>\n",
       "      <td>1717.69</td>\n",
       "      <td>7.00</td>\n",
       "      <td>-1494742.0</td>\n",
       "      <td>-189254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>539279</td>\n",
       "      <td>1710.72</td>\n",
       "      <td>1717.84</td>\n",
       "      <td>7.12</td>\n",
       "      <td>189254.0</td>\n",
       "      <td>448332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>90947</td>\n",
       "      <td>1710.75</td>\n",
       "      <td>1717.85</td>\n",
       "      <td>7.10</td>\n",
       "      <td>-448332.0</td>\n",
       "      <td>-149709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>240656</td>\n",
       "      <td>1710.79</td>\n",
       "      <td>1717.94</td>\n",
       "      <td>7.15</td>\n",
       "      <td>149709.0</td>\n",
       "      <td>15977.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>224679</td>\n",
       "      <td>1710.80</td>\n",
       "      <td>1717.88</td>\n",
       "      <td>7.08</td>\n",
       "      <td>-15977.0</td>\n",
       "      <td>-1727189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>1951868</td>\n",
       "      <td>1710.86</td>\n",
       "      <td>1718.03</td>\n",
       "      <td>7.17</td>\n",
       "      <td>1727189.0</td>\n",
       "      <td>499337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>1452531</td>\n",
       "      <td>1710.98</td>\n",
       "      <td>1718.09</td>\n",
       "      <td>7.11</td>\n",
       "      <td>-499337.0</td>\n",
       "      <td>462903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>989628</td>\n",
       "      <td>1711.30</td>\n",
       "      <td>1718.24</td>\n",
       "      <td>6.94</td>\n",
       "      <td>-462903.0</td>\n",
       "      <td>504679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>484949</td>\n",
       "      <td>1713.59</td>\n",
       "      <td>1718.38</td>\n",
       "      <td>4.79</td>\n",
       "      <td>-504679.0</td>\n",
       "      <td>-42267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>527216</td>\n",
       "      <td>1713.59</td>\n",
       "      <td>1718.37</td>\n",
       "      <td>4.78</td>\n",
       "      <td>42267.0</td>\n",
       "      <td>-986611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5091</th>\n",
       "      <td>1513827</td>\n",
       "      <td>1713.61</td>\n",
       "      <td>1718.36</td>\n",
       "      <td>4.75</td>\n",
       "      <td>986611.0</td>\n",
       "      <td>-845094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>2358921</td>\n",
       "      <td>1713.67</td>\n",
       "      <td>1718.48</td>\n",
       "      <td>4.81</td>\n",
       "      <td>845094.0</td>\n",
       "      <td>228624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>2130297</td>\n",
       "      <td>1713.69</td>\n",
       "      <td>1718.43</td>\n",
       "      <td>4.74</td>\n",
       "      <td>-228624.0</td>\n",
       "      <td>1630685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>499612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1630685.0</td>\n",
       "      <td>-140529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>640141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140529.0</td>\n",
       "      <td>-190941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>831082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190941.0</td>\n",
       "      <td>-151924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344</th>\n",
       "      <td>983006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151924.0</td>\n",
       "      <td>-767178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>1750184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767178.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  mindate  maxdate  diff  df_id_diff  df_id_diff_reverse\n",
       "3616  1060450     0.09     1.48  1.39         NaN           -195631.0\n",
       "4265  1256081     0.29     1.68  1.39    195631.0            784399.0\n",
       "1627   471682     0.39     0.46  0.07   -784399.0            377088.0\n",
       "324     94594     0.41     1.62  1.21   -377088.0           -381493.0\n",
       "1613   476087     0.41     1.63  1.22    381493.0            325086.0\n",
       "532    151001     0.43     1.59  1.16   -325086.0           -431925.0\n",
       "1960   582926     0.47     0.51  0.04    431925.0          -1008321.0\n",
       "5350  1591247     0.52     1.73  1.21   1008321.0            103192.0\n",
       "5079  1488055     0.60     1.38  0.78   -103192.0           -292243.0\n",
       "5972  1780298     0.61     1.05  0.44    292243.0            611695.0\n",
       "3990  1168603     0.63     1.92  1.29   -611695.0            540253.0\n",
       "2153   628350     0.64     3.08  2.44   -540253.0            -12394.0\n",
       "2164   640744     0.64     1.91  1.27     12394.0            554192.0\n",
       "304     86552     0.68     0.71  0.03   -554192.0             20688.0\n",
       "214     65864     0.71     0.75  0.04    -20688.0          -1163392.0\n",
       "4166  1229256     0.71     1.81  1.10   1163392.0           -208687.0\n",
       "4858  1437943     0.75     0.79  0.04    208687.0            411090.0\n",
       "3497  1026853     0.76     0.79  0.03   -411090.0            -21743.0\n",
       "3561  1048596     0.79     0.81  0.02     21743.0          -1083444.0\n",
       "7176  2132040     0.81     2.07  1.26   1083444.0            417361.0\n",
       "5773  1714679     0.82     2.09  1.27   -417361.0            769428.0\n",
       "3214   945251     0.84     0.87  0.03   -769428.0           -156690.0\n",
       "3777  1101941     0.85     0.88  0.03    156690.0           -229849.0\n",
       "4519  1331790     0.86     0.89  0.03    229849.0           -552936.0\n",
       "6319  1884726     0.88     2.06  1.18    552936.0            876444.0\n",
       "3438  1008282     0.91     0.98  0.07   -876444.0           -709138.0\n",
       "5781  1717420     0.97     2.28  1.31    709138.0            324426.0\n",
       "4713  1392994     0.98     1.41  0.43   -324426.0           -213540.0\n",
       "5464  1606534     1.00     2.24  1.24    213540.0           1116452.0\n",
       "1683   490082     1.04     1.06  0.02  -1116452.0          -1164025.0\n",
       "...       ...      ...      ...   ...         ...                 ...\n",
       "5635  1663675  1710.17  1713.70  3.53   -589427.0           -101804.0\n",
       "5948  1765479  1710.21  1714.04  3.83    101804.0            987906.0\n",
       "2626   777573  1710.22  1714.01  3.79   -987906.0           -775674.0\n",
       "5287  1553247  1710.27  1713.99  3.72    775674.0           -686964.0\n",
       "7562  2240211  1710.33  1714.18  3.85    686964.0           1577430.0\n",
       "2245   662781  1710.34  1714.18  3.84  -1577430.0             35934.0\n",
       "2150   626847  1710.37  1714.13  3.76    -35934.0            212703.0\n",
       "1423   414144  1710.44  1717.61  7.17   -212703.0          -1549871.0\n",
       "6638  1964015  1710.44  1717.68  7.24   1549871.0             -6853.0\n",
       "6639  1970868  1710.48  1714.30  3.82      6853.0            284032.0\n",
       "5681  1686836  1710.50  1715.66  5.16   -284032.0           -157931.0\n",
       "6182  1844767  1710.61  1715.67  5.06    157931.0           1494742.0\n",
       "1204   350025  1710.69  1717.69  7.00  -1494742.0           -189254.0\n",
       "1859   539279  1710.72  1717.84  7.12    189254.0            448332.0\n",
       "316     90947  1710.75  1717.85  7.10   -448332.0           -149709.0\n",
       "853    240656  1710.79  1717.94  7.15    149709.0             15977.0\n",
       "794    224679  1710.80  1717.88  7.08    -15977.0          -1727189.0\n",
       "6565  1951868  1710.86  1718.03  7.17   1727189.0            499337.0\n",
       "4967  1452531  1710.98  1718.09  7.11   -499337.0            462903.0\n",
       "3369   989628  1711.30  1718.24  6.94   -462903.0            504679.0\n",
       "1635   484949  1713.59  1718.38  4.79   -504679.0            -42267.0\n",
       "1819   527216  1713.59  1718.37  4.78     42267.0           -986611.0\n",
       "5091  1513827  1713.61  1718.36  4.75    986611.0           -845094.0\n",
       "7975  2358921  1713.67  1718.48  4.81    845094.0            228624.0\n",
       "7180  2130297  1713.69  1718.43  4.74   -228624.0           1630685.0\n",
       "1686   499612      NaN      NaN   NaN  -1630685.0           -140529.0\n",
       "2196   640141      NaN      NaN   NaN    140529.0           -190941.0\n",
       "2820   831082      NaN      NaN   NaN    190941.0           -151924.0\n",
       "3344   983006      NaN      NaN   NaN    151924.0           -767178.0\n",
       "5909  1750184      NaN      NaN   NaN    767178.0                 NaN\n",
       "\n",
       "[16000 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cat_date_preprosess(visible, blind, column_name):\n",
    "    outcomes = visible.groupby(column_name)['Response'].mean().reset_index()\n",
    "    x = pd.merge(blind[[column_name, 'Response']], outcomes,\n",
    "                 suffixes=('_', ''),\n",
    "                 how='left',\n",
    "                 on=column_name,\n",
    "                 left_index=True)['Response']\n",
    "    return x.fillna(x.mean())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "   #trainfiles = ['D:/Project/Sample data/Sam_8/train_categorical.csv']\n",
    "    trainfiles = ['D:/Project/Sample data/Sam_8/train_categorical.csv','D:/Project/Sample data/Sam_8/train_date.csv','D:/Project/Sample data/Sam_8/train_numeric.csv']\n",
    "    #testfiles = ['D:/Project/Sample data/Sam_Test_8/test_categorical.csv']\n",
    "\n",
    "    testfiles = ['D:/Project/Sample data/Sam_Test_8/test_categorical.csv','D:/Project/Sample data/Sam_Test_8/test_date.csv', 'D:/Project/Sample data/Sam_Test_8/test_numeric.csv']\n",
    "\n",
    "    cols = [['Id',\n",
    "             'L1_S24_F1559', 'L3_S32_F3851',\n",
    "             'L1_S24_F1827', 'L1_S24_F1582',\n",
    "             'L3_S32_F3854', 'L1_S24_F1510',\n",
    "             #'L1_S24_F1525', \n",
    "             'L3_S29_F3481',\n",
    "             'L2_S26_F3097', 'L2_S27_F3220',\n",
    "             'L2_S27_F3192', 'L3_S29_F3493',\n",
    "             #'L1_S24_F675', \n",
    "             'L3_S47_F4191',\n",
    "            ],\n",
    "            ['Id',\n",
    "             'L3_S30_D3496', 'L3_S30_D3506',\n",
    "             'L3_S30_D3501', 'L3_S30_D3516',\n",
    "             'L3_S30_D3511', 'L3_S37_D3951',\n",
    "             'L3_S34_D3883', 'L3_S47_D4190',\n",
    "             'L3_S38_D3961', 'L3_S32_D3852',\n",
    "             'L3_S29_D3480', 'L0_S4_D106',\n",
    "             'L0_S3_D102',   'L3_S35_D3891',\n",
    "             'L0_S1_D26',    #'L0_S21_D484',\n",
    "             'L3_S36_D3940', 'L0_S16_D428', \n",
    "             'L3_S33_D3874', 'L3_S36_D3925',\n",
    "             'L2_S26_D3096', 'L2_S27_D3219',\n",
    "             'L0_S0_D23',    'L3_S29_D3492',\n",
    "             'L0_S11_D328',  'L0_S10_D231', \n",
    "\n",
    "            ],\n",
    "            ['Id',\n",
    "             'L1_S24_F1846', 'L3_S32_F3850',\n",
    "             'L1_S24_F1695', 'L1_S24_F1632',\n",
    "             'L3_S33_F3855', 'L1_S24_F1604',\n",
    "             'L3_S29_F3407', 'L3_S33_F3865',\n",
    "             'L3_S38_F3952', 'L1_S24_F1723',\n",
    "             'L3_S38_F3960', 'L3_S33_F3865', \n",
    "             'L3_S38_F3956', 'L3_S33_F3857',\n",
    "             'L3_S29_F3321', 'L1_S24_F1846', \n",
    "             'L3_S29_F3354', 'L3_S29_F3324', \n",
    "             'L3_S35_F3889', 'L0_S1_F28', \n",
    "             'L1_S24_F1844', 'L3_S29_F3376', \n",
    "             'L0_S0_F22',    'L3_S33_F3859',  \n",
    "             'L3_S30_F3754', 'L2_S26_F3113', \n",
    "             'L3_S30_F3759', 'L0_S5_F114',\n",
    "             'L3_S29_F3339', 'L3_S30_F3804',\n",
    "             'L3_S29_F3351', 'L3_S30_F3704',   \n",
    "             \n",
    "             'Response',]]\n",
    "\n",
    "    traindata = None\n",
    "    testdata = None\n",
    "    for i, f in enumerate(trainfiles):\n",
    "        #print(\"i\", i)\n",
    "        #print(\"f\",f)\n",
    "        subset = None\n",
    "        for i, chunk in enumerate(pd.read_csv(f,\n",
    "                                              usecols=cols[i],\n",
    "                                              chunksize=1000,\n",
    "                                              low_memory=False)):\n",
    "           #print(\"i\", i)\n",
    "            #print(chunk)\n",
    "            if subset is None:\n",
    "                subset = chunk.copy()\n",
    "            else:\n",
    "\n",
    "                subset = pd.concat([subset, chunk])\n",
    "            \n",
    "            #rint(subset)\n",
    "\n",
    "            del chunk\n",
    "            #print(subset)\n",
    "            gc.collect()\n",
    "        if traindata is None:\n",
    "            traindata = subset.copy()\n",
    "        else:\n",
    "            traindata = pd.merge(traindata, subset.copy(), on=\"Id\")\n",
    "        del subset\n",
    "        gc.collect()\n",
    "  \n",
    "    traindata['magic'] = traindata['L3_S33_F3855'].pct_change()\n",
    "    traindata['magic2'] = traindata['L3_S29_F3407'].pct_change()\n",
    "    traindata['magic5'] = traindata['L3_S29_F3354'].pct_change()\n",
    "    traindata['magic6'] = traindata['L3_S29_F3321'].pct_change()\n",
    "    traindata['magic7'] = traindata['L3_S38_F3952'].pct_change()\n",
    "#    traindata['magic8'] = traindata['L1_S24_F1604'].pct_change()\n",
    "    \n",
    "#    traindata['magic9'] = traindata['L3_S33_F3859'].pct_change()\n",
    "#    traindata['magic10'] = traindata['L0_S0_F22'].pct_change() \n",
    "#    traindata['magic11'] = traindata['L3_S33_F3857'].pct_change()\n",
    "\n",
    "#    traindata['magic13'] = traindata['L3_S30_F3804'].pct_change()\n",
    "#    \n",
    "#    traindata['magic14'] = traindata['L3_S30_F3754'].pct_change()\n",
    "#    traindata['magic15'] = traindata['L1_S24_F1844'].pct_change()\n",
    "#    traindata['magic16'] = traindata['L3_S38_F3956'].pct_change()\n",
    "#    traindata['magic17'] = traindata['L3_S32_F3850'].pct_change()\n",
    "\n",
    "#    traindata['magic19'] = traindata['L3_S29_F3351'].pct_change()\n",
    "\n",
    "    del cols[2][-1] \n",
    "    for i, f in enumerate(testfiles):\n",
    "        #rint(f)\n",
    "        subset = None\n",
    "        for i, chunk in enumerate(pd.read_csv(f,\n",
    "                                              usecols=cols[i],\n",
    "                                              chunksize=1000,\n",
    "                                              low_memory=False)):\n",
    "            #rint(i)\n",
    "            if subset is None:\n",
    "                subset = chunk.copy()\n",
    "            else:\n",
    "\n",
    "                subset = pd.concat([subset, chunk]) \n",
    "                \n",
    "            del chunk\n",
    "            gc.collect()\n",
    "        if testdata is None:\n",
    "            testdata = subset.copy()\n",
    "        else:\n",
    "            testdata = pd.merge(testdata, subset.copy(), on=\"Id\")\n",
    "        del subset\n",
    "        gc.collect()\n",
    "    \n",
    "    testdata['magic'] = testdata['L3_S33_F3855'].pct_change()\n",
    "    testdata['magic2'] = testdata['L3_S29_F3407'].pct_change()\n",
    "    testdata['magic5'] = testdata['L3_S29_F3354'].pct_change()\n",
    "    testdata['magic6'] = testdata['L3_S29_F3321'].pct_change()\n",
    "    testdata['magic7'] = testdata['L3_S38_F3952'].pct_change()\n",
    "#    testdata['magic8'] = testdata['L1_S24_F1604'].pct_change()\n",
    "    \n",
    "#    testdata['magic10'] = testdata['L0_S0_F22'].pct_change() \n",
    "#    testdata['magic11'] = testdata['L3_S33_F3857'].pct_change()\n",
    "\n",
    "#    testdata['magic13'] = testdata['L3_S30_F3804'].pct_change()\n",
    "#    \n",
    "#    testdata['magic14'] = testdata['L3_S30_F3754'].pct_change()\n",
    "#    testdata['magic15'] = testdata['L1_S24_F1844'].pct_change()\n",
    "#    testdata['magic16'] = testdata['L3_S38_F3956'].pct_change()\n",
    "#    testdata['magic17'] = testdata['L3_S32_F3850'].pct_change()\n",
    "#    testdata['magic19'] = testdata['L3_S29_F3351'].pct_change()\n",
    "   \n",
    "    traindata = traindata.merge(date_pros, on='Id')\n",
    "    testdata = testdata.merge(date_pros, on='Id')    \n",
    "    testdata['Response'] = 0  \n",
    "    \n",
    "    cols = [['Id',\n",
    "             'L1_S24_F1559', 'L3_S32_F3851',\n",
    "             'L1_S24_F1827', 'L1_S24_F1582',\n",
    "             'L3_S32_F3854', 'L1_S24_F1510',\n",
    "             #'L1_S24_F1525', \n",
    "             'L3_S29_F3481',\n",
    "             'L2_S26_F3097', 'L2_S27_F3220',\n",
    "             'L2_S27_F3192', 'L3_S29_F3493',\n",
    "             #'L1_S24_F675',  \n",
    "             'L3_S47_F4191',\n",
    "\n",
    "            ],\n",
    "            ['Id',\n",
    "             'L3_S30_D3496', 'L3_S30_D3506',\n",
    "             'L3_S30_D3501', 'L3_S30_D3516',\n",
    "             'L3_S30_D3511', 'L3_S37_D3951',\n",
    "             'L3_S34_D3883', 'L3_S47_D4190',\n",
    "             'L3_S38_D3961', 'L3_S32_D3852',\n",
    "             'L3_S29_D3480', 'L0_S4_D106',\n",
    "             'L0_S3_D102',   'L3_S35_D3891',\n",
    "             'L0_S1_D26',    #'L0_S21_D484',\n",
    "             'L3_S36_D3940', 'L0_S16_D428', \n",
    "             'L3_S33_D3874', 'L3_S36_D3925',\n",
    "             'L2_S26_D3096', 'L2_S27_D3219',\n",
    "             'L0_S0_D23',    'L3_S29_D3492',\n",
    "             'L0_S11_D328',  'L0_S10_D231', \n",
    "\n",
    "            ],\n",
    "            ['Id',\n",
    "             'L1_S24_F1846', 'L3_S32_F3850',\n",
    "             'L1_S24_F1695', 'L1_S24_F1632',\n",
    "             'L3_S33_F3855', 'L1_S24_F1604',\n",
    "             'L3_S29_F3407', 'L3_S33_F3865',\n",
    "             'L3_S38_F3952', 'L1_S24_F1723',\n",
    "             'L3_S38_F3960', 'L3_S33_F3865', \n",
    "             'L3_S38_F3956', 'L3_S33_F3857',\n",
    "             'L3_S29_F3321', 'L1_S24_F1846', \n",
    "             'L3_S29_F3354', 'L3_S29_F3324', \n",
    "             'L3_S35_F3889', 'L0_S1_F28', \n",
    "             'L1_S24_F1844', 'L3_S29_F3376', \n",
    "             'L0_S0_F22',    'L3_S33_F3859',  \n",
    "             'L3_S30_F3754', 'L2_S26_F3113', \n",
    "             'L3_S30_F3759', 'L0_S5_F114',\n",
    "             'L3_S29_F3339', 'L3_S30_F3804',\n",
    "             'L3_S29_F3351',  'L3_S30_F3704',\n",
    "             'Response', 'magic', 'magic2', \n",
    "             'magic5', 'magic6','magic7',\n",
    "#             'magic8', 'magic9', 'magic10', 'magic11', 'magic13',\n",
    "#             'magic14', 'magic15', 'magic16', 'magic17', 'magic19',\n",
    "            ]]\n",
    "    \n",
    "    ntrain = traindata.shape[0]\n",
    "    ntest = testdata.shape[0]\n",
    "    train_test = pd.concat((traindata, testdata)).reset_index(drop=True)\n",
    "       \n",
    "    numeric_feats = \\\n",
    "            [\n",
    "             'L1_S24_F1846', 'L3_S32_F3850',\n",
    "             'L1_S24_F1695', 'L1_S24_F1632',\n",
    "             'L3_S33_F3855', 'L1_S24_F1604',\n",
    "             'L3_S29_F3407', 'L3_S33_F3865',\n",
    "             'L3_S38_F3952', 'L1_S24_F1723',\n",
    "             'L3_S38_F3960', 'L3_S33_F3865', \n",
    "             'L3_S38_F3956', 'L3_S33_F3857',\n",
    "             'L3_S29_F3321', 'L1_S24_F1846', \n",
    "             'L3_S29_F3354', 'L3_S29_F3324', \n",
    "             'L3_S35_F3889', 'L0_S1_F28', \n",
    "             'L1_S24_F1844', 'L3_S29_F3376', \n",
    "             'L0_S0_F22',    'L3_S33_F3859',  \n",
    "             'L3_S30_F3754', 'L2_S26_F3113', \n",
    "             'L3_S30_F3759', 'L0_S5_F114',\n",
    "             'L3_S29_F3339', 'L3_S30_F3804',\n",
    "             'L3_S29_F3351',  'L3_S30_F3704',\n",
    "             'magic', 'magic2', 'magic5', 'magic6', 'magic7',\n",
    "#             'magic8', 'magic9', 'magic10', 'magic11', 'magic13',        \n",
    "#             'magic14', 'magic15', 'magic16', 'magic17', 'magic19',\n",
    "    ]\n",
    "\n",
    "    skewed_feats = train_test[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    print(\"\\nSkew in numeric features:\")\n",
    "    print(skewed_feats)\n",
    "    skewed_feats = skewed_feats[np.absolute(skewed_feats) > 0.2]\n",
    "    skewed_feats = skewed_feats.index\n",
    "    for feats in skewed_feats:\n",
    "        train_test[feats] = train_test[feats] + 1000\n",
    "        train_test[feats], lam = boxcox(train_test[feats])                \n",
    "    \n",
    "    traindata = train_test.iloc[:ntrain, :]\n",
    "    testdata = train_test.iloc[ntrain:, :]\n",
    "     \n",
    "    return traindata, testdata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:204: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:1031: RuntimeWarning: invalid value encountered in less_equal\n",
      "  if any(x <= 0):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numeric features:\n",
      "L1_S24_F1846   -0.115297\n",
      "L3_S32_F3850   -0.097011\n",
      "L1_S24_F1695    2.295745\n",
      "L1_S24_F1632   -0.256862\n",
      "L3_S33_F3855    0.067550\n",
      "L1_S24_F1604    1.599911\n",
      "L3_S29_F3407   -2.881485\n",
      "L3_S33_F3865   -0.146548\n",
      "L3_S38_F3952   -0.725198\n",
      "L1_S24_F1723   -0.427800\n",
      "L3_S38_F3960    1.387486\n",
      "L3_S33_F3865   -0.146548\n",
      "L3_S38_F3956   -0.036244\n",
      "L3_S33_F3857    0.040891\n",
      "L3_S29_F3321    0.657533\n",
      "L1_S24_F1846   -0.115297\n",
      "L3_S29_F3354    0.137426\n",
      "L3_S29_F3324    0.535930\n",
      "L3_S35_F3889    0.516382\n",
      "L0_S1_F28       0.599846\n",
      "L1_S24_F1844    0.079127\n",
      "L3_S29_F3376    0.426489\n",
      "L0_S0_F22       0.094776\n",
      "L3_S33_F3859   -0.291161\n",
      "L3_S30_F3754   -1.168406\n",
      "L2_S26_F3113    0.083748\n",
      "L3_S30_F3759    0.577946\n",
      "L0_S5_F114     -0.394970\n",
      "L3_S29_F3339   -0.030512\n",
      "L3_S30_F3804   -3.485517\n",
      "L3_S29_F3351   -0.388367\n",
      "L3_S30_F3704   -0.141159\n",
      "magic           0.008430\n",
      "magic2         -4.807247\n",
      "magic5          0.077453\n",
      "magic6          3.960617\n",
      "magic7         -7.739565\n",
      "dtype: float64\n",
      "Train shape: (8000, 79)\n",
      "Test shape: (8000, 79)\n",
      "['L0_S0_D23', 'L0_S0_F22', 'L0_S10_D231', 'L0_S11_D328', 'L0_S16_D428', 'L0_S1_D26', 'L0_S1_F28', 'L0_S3_D102', 'L0_S4_D106', 'L0_S5_F114', 'L1_S24_F1510', 'L1_S24_F1559', 'L1_S24_F1582', 'L1_S24_F1604', 'L1_S24_F1632', 'L1_S24_F1695', 'L1_S24_F1723', 'L1_S24_F1827', 'L1_S24_F1844', 'L1_S24_F1846', 'L2_S26_D3096', 'L2_S26_F3097', 'L2_S26_F3113', 'L2_S27_D3219', 'L2_S27_F3192', 'L2_S27_F3220', 'L3_S29_D3480', 'L3_S29_D3492', 'L3_S29_F3321', 'L3_S29_F3324', 'L3_S29_F3339', 'L3_S29_F3351', 'L3_S29_F3354', 'L3_S29_F3376', 'L3_S29_F3407', 'L3_S29_F3481', 'L3_S29_F3493', 'L3_S30_D3496', 'L3_S30_D3501', 'L3_S30_D3506', 'L3_S30_D3511', 'L3_S30_D3516', 'L3_S30_F3704', 'L3_S30_F3754', 'L3_S30_F3759', 'L3_S30_F3804', 'L3_S32_D3852', 'L3_S32_F3850', 'L3_S32_F3851', 'L3_S32_F3854', 'L3_S33_D3874', 'L3_S33_F3855', 'L3_S33_F3857', 'L3_S33_F3859', 'L3_S33_F3865', 'L3_S34_D3883', 'L3_S35_D3891', 'L3_S35_F3889', 'L3_S36_D3925', 'L3_S36_D3940', 'L3_S37_D3951', 'L3_S38_D3961', 'L3_S38_F3952', 'L3_S38_F3956', 'L3_S38_F3960', 'L3_S47_D4190', 'L3_S47_F4191', 'df_id_diff', 'df_id_diff_reverse', 'diff', 'magic', 'magic2', 'magic5', 'magic6', 'magic7', 'maxdate', 'mindate']\n",
      "mcc <function mcc at 0x00000278D13B1950>\n",
      "score make_scorer(mcc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.000000\n",
      "1     0.363980\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "5     0.846943\n",
      "6     0.987279\n",
      "7     0.111538\n",
      "8     0.000000\n",
      "9     0.000000\n",
      "10    0.111538\n",
      "11    0.000000\n",
      "12    0.387830\n",
      "13    0.524307\n",
      "14    0.000000\n",
      "15    0.732720\n",
      "16    0.673423\n",
      "17    0.387830\n",
      "18    0.000000\n",
      "19    0.000000\n",
      "20    0.000000\n",
      "21    0.694387\n",
      "22    0.987279\n",
      "Name: mean_train_score, dtype: float64\n",
      "0     0.000000\n",
      "1     0.000000\n",
      "2     0.000000\n",
      "3     0.000000\n",
      "4     0.000000\n",
      "5     0.000000\n",
      "6     0.000000\n",
      "7     0.000000\n",
      "8     0.000000\n",
      "9     0.000000\n",
      "10    0.000000\n",
      "11    0.000000\n",
      "12    0.000000\n",
      "13    0.000000\n",
      "14    0.000000\n",
      "15    0.114421\n",
      "16    0.000000\n",
      "17    0.000000\n",
      "18    0.000000\n",
      "19    0.000000\n",
      "20    0.000000\n",
      "21   -0.000546\n",
      "22    0.000000\n",
      "Name: mean_test_score, dtype: float64\n",
      "mean_fit_time\n",
      "std_fit_time\n",
      "mean_score_time\n",
      "std_score_time\n",
      "param_objective\n",
      "param_n_estimators\n",
      "param_min_child_weight\n",
      "param_max_depth\n",
      "param_learning_rate\n",
      "param_gamma\n",
      "param_base_score\n",
      "params\n",
      "split0_test_score\n",
      "split1_test_score\n",
      "mean_test_score\n",
      "std_test_score\n",
      "rank_test_score\n",
      "split0_train_score\n",
      "split1_train_score\n",
      "mean_train_score\n",
      "std_train_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "    \n",
    "start_time = timer(None)\n",
    "\n",
    "train, test = data()\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "\n",
    "features = list(train.columns)\n",
    "features.remove('Response')\n",
    "features.remove('Id')\n",
    "print(features)\n",
    "\n",
    "X = train[features]\n",
    "y = train['Response'] \n",
    "parameters = { 'n_estimators': [ 100, 150, 200],\n",
    "               'objective' : ['binary:logistic'],\n",
    "               'learning_rate' : [0.02, 0.05, 0.1],\n",
    "               'max_depth' : [9, 10, 12, 15], \n",
    "               'base_score' : [0.0056],  \n",
    "               'min_child_weight': [ 2, 4, 6],  \n",
    "               'gamma' : [0, 0.2, 1],\n",
    "\n",
    " }\n",
    "'''\n",
    "def mcc(y, preds):\n",
    "    thresholds = np.linspace(0.01, 0.99, 50)\n",
    "    mcc_ = np.array([matthews_corrcoef(y, preds>thr) for thr in thresholds])\n",
    "    best_threshold = thresholds[mcc_.argmax()]\n",
    "    return mcc_.max()\n",
    "'''\n",
    "ssscv = StratifiedKFold( n_splits=2, shuffle=True, random_state=0) # 1. Let's build a stratified shuffle object\n",
    "ssscv.get_n_splits(X, y)\n",
    "print (\"mcc\", mcc)\n",
    "score = make_scorer(mcc, greater_is_better=True)\n",
    "print (\"score:\", score)\n",
    "grid = RandomizedSearchCV(XGBClassifier(),\n",
    "                          param_distributions=parameters,\n",
    "                          n_iter=23,\n",
    "                          cv=ssscv, \n",
    "                          scoring=score,\n",
    "\n",
    "                         ) # 2. Let's now we pass the object and the parameters to grid search\n",
    "grid.fit(X, y) # 3. Let's fit it\n",
    "\n",
    "best = grid.best_estimator_\n",
    "\n",
    "#for params, mean_train_score in grid.cv_results_ :\n",
    "    #print(\"%0.3f (+/-%0.3f) for %r\" % (mean_train_score.mean(), mean_train_score.std(), params))\n",
    "#print\n",
    "\n",
    "import pandas as pd\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "print(cv_results['mean_train_score'])\n",
    "print(cv_results['mean_test_score'])\n",
    "\n",
    "for g in grid.cv_results_: print(g)\n",
    "\n",
    "#print(grid.best_score_)\n",
    "#print(grid.best_estimator_)\n",
    "#print(\"Best params: {}\".format( grid.best_params_))\n",
    "\n",
    "\n",
    "#print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv(\"D:/Project/final.csv\", header= True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time\n",
      "std_fit_time\n",
      "mean_score_time\n",
      "std_score_time\n",
      "param_objective\n",
      "param_n_estimators\n",
      "param_min_child_weight\n",
      "param_max_depth\n",
      "param_learning_rate\n",
      "param_gamma\n",
      "param_base_score\n",
      "params\n",
      "split0_test_score\n",
      "split1_test_score\n",
      "mean_test_score\n",
      "std_test_score\n",
      "rank_test_score\n",
      "split0_train_score\n",
      "split1_train_score\n",
      "mean_train_score\n",
      "std_train_score\n"
     ]
    }
   ],
   "source": [
    "for g in grid.cv_results_:\n",
    "    \n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23, 21)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'n_estimators'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-5f05ca4e6dda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_estimators\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'n_estimators'"
     ]
    }
   ],
   "source": [
    "print(cv_results[\"n_estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([[\n",
    "        cv_results['mean_train_score'],\n",
    "        cv_results['param_n_estimators']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(scores[:,1], scores[:, 0])\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('mean_train_score')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([[\n",
    "        cv_results['mean_train_score'],\n",
    "        cv_results['param_gamma']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mean_train_score')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(scores[:,1], scores[:, 0])\n",
    "plt.xlabel('param_gamma')\n",
    "plt.ylabel('mean_train_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.36397969344181924, 0.0, 0.8469433191872511, 0.0, 0.0, 0.0,\n",
       "         0.0, 0.11153754973102109, 0.0, 0.19323701838063098,\n",
       "         0.36397969344181924, 0.5909924181515112, 0.38783035437756136,\n",
       "         0.0, 0.0, 0.11153754973102109, 0.0, 0.36397969344181924,\n",
       "         0.7327201698509269, 0.11153754973102109, 0.0,\n",
       "         0.36397969344181924, 0.0],\n",
       "        [200, 200, 100, 150, 150, 200, 100, 150, 100, 200, 200, 200,\n",
       "         200, 150, 100, 150, 100, 200, 150, 150, 100, 200, 200]]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     200\n",
      "1     200\n",
      "2     100\n",
      "3     150\n",
      "4     150\n",
      "5     200\n",
      "6     100\n",
      "7     150\n",
      "8     100\n",
      "9     200\n",
      "10    200\n",
      "11    200\n",
      "12    200\n",
      "13    150\n",
      "14    100\n",
      "15    150\n",
      "16    100\n",
      "17    200\n",
      "18    150\n",
      "19    150\n",
      "20    100\n",
      "21    200\n",
      "22    200\n",
      "Name: param_n_estimators, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['param_n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>...</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.226849</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>0.273350</td>\n",
       "      <td>0.013051</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228899</td>\n",
       "      <td>0.499061</td>\n",
       "      <td>0.363980</td>\n",
       "      <td>0.135081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.110677</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.348067</td>\n",
       "      <td>0.093753</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.326785</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.333136</td>\n",
       "      <td>0.063826</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.857856</td>\n",
       "      <td>0.836030</td>\n",
       "      <td>0.846943</td>\n",
       "      <td>0.010913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.970756</td>\n",
       "      <td>0.008958</td>\n",
       "      <td>0.255333</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.086478</td>\n",
       "      <td>0.090705</td>\n",
       "      <td>0.234858</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.612026</td>\n",
       "      <td>0.089764</td>\n",
       "      <td>0.253854</td>\n",
       "      <td>0.024434</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.640515</td>\n",
       "      <td>0.313064</td>\n",
       "      <td>0.371014</td>\n",
       "      <td>0.104725</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.164628</td>\n",
       "      <td>0.105018</td>\n",
       "      <td>0.323163</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223075</td>\n",
       "      <td>0.111538</td>\n",
       "      <td>0.111538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.981806</td>\n",
       "      <td>0.050788</td>\n",
       "      <td>0.293474</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.388948</td>\n",
       "      <td>0.055286</td>\n",
       "      <td>0.289210</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386474</td>\n",
       "      <td>0.193237</td>\n",
       "      <td>0.193237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.106272</td>\n",
       "      <td>0.288326</td>\n",
       "      <td>0.282027</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228899</td>\n",
       "      <td>0.499061</td>\n",
       "      <td>0.363980</td>\n",
       "      <td>0.135081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.135704</td>\n",
       "      <td>0.128821</td>\n",
       "      <td>0.294454</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.512089</td>\n",
       "      <td>0.669896</td>\n",
       "      <td>0.590992</td>\n",
       "      <td>0.078903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.411374</td>\n",
       "      <td>0.132960</td>\n",
       "      <td>0.281740</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228899</td>\n",
       "      <td>0.546762</td>\n",
       "      <td>0.387830</td>\n",
       "      <td>0.158932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.880463</td>\n",
       "      <td>0.065179</td>\n",
       "      <td>0.277970</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.781580</td>\n",
       "      <td>0.027674</td>\n",
       "      <td>0.268522</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.888139</td>\n",
       "      <td>0.071393</td>\n",
       "      <td>0.304442</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223075</td>\n",
       "      <td>0.111538</td>\n",
       "      <td>0.111538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.160411</td>\n",
       "      <td>0.280734</td>\n",
       "      <td>0.260317</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.606717</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.329629</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228899</td>\n",
       "      <td>0.499061</td>\n",
       "      <td>0.363980</td>\n",
       "      <td>0.135081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.850152</td>\n",
       "      <td>0.148321</td>\n",
       "      <td>0.273788</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228899</td>\n",
       "      <td>0.114421</td>\n",
       "      <td>0.114449</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724657</td>\n",
       "      <td>0.740783</td>\n",
       "      <td>0.732720</td>\n",
       "      <td>0.008063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.580515</td>\n",
       "      <td>0.019706</td>\n",
       "      <td>0.286235</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223075</td>\n",
       "      <td>0.111538</td>\n",
       "      <td>0.111538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.351246</td>\n",
       "      <td>0.035605</td>\n",
       "      <td>0.263795</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.292196</td>\n",
       "      <td>0.243751</td>\n",
       "      <td>0.270296</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228899</td>\n",
       "      <td>0.499061</td>\n",
       "      <td>0.363980</td>\n",
       "      <td>0.135081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.403671</td>\n",
       "      <td>0.023336</td>\n",
       "      <td>0.258276</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>{'objective': 'binary:logistic', 'n_estimators...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        3.226849      0.014582         0.273350        0.013051   \n",
       "1        3.110677      0.252632         0.348067        0.093753   \n",
       "2        2.326785      0.046875         0.333136        0.063826   \n",
       "3        1.970756      0.008958         0.255333        0.008960   \n",
       "4        2.086478      0.090705         0.234858        0.008462   \n",
       "5        2.612026      0.089764         0.253854        0.024434   \n",
       "6        1.640515      0.313064         0.371014        0.104725   \n",
       "7        2.164628      0.105018         0.323163        0.018921   \n",
       "8        1.981806      0.050788         0.293474        0.004245   \n",
       "9        2.388948      0.055286         0.289210        0.018933   \n",
       "10       5.106272      0.288326         0.282027        0.011238   \n",
       "11       3.135704      0.128821         0.294454        0.024210   \n",
       "12       3.411374      0.132960         0.281740        0.001526   \n",
       "13       3.880463      0.065179         0.277970        0.002742   \n",
       "14       1.781580      0.027674         0.268522        0.001236   \n",
       "15       1.888139      0.071393         0.304442        0.010267   \n",
       "16       2.160411      0.280734         0.260317        0.001983   \n",
       "17       3.606717      0.028569         0.329629        0.002485   \n",
       "18       3.850152      0.148321         0.273788        0.001480   \n",
       "19       2.580515      0.019706         0.286235        0.006981   \n",
       "20       1.351246      0.035605         0.263795        0.014462   \n",
       "21       5.292196      0.243751         0.270296        0.009953   \n",
       "22       2.403671      0.023336         0.258276        0.003989   \n",
       "\n",
       "    param_objective param_n_estimators param_min_child_weight param_max_depth  \\\n",
       "0   binary:logistic                200                      4               9   \n",
       "1   binary:logistic                200                      6              12   \n",
       "2   binary:logistic                100                      2               9   \n",
       "3   binary:logistic                150                      6               9   \n",
       "4   binary:logistic                150                      6              10   \n",
       "5   binary:logistic                200                      6              15   \n",
       "6   binary:logistic                100                      6               9   \n",
       "7   binary:logistic                150                      6              12   \n",
       "8   binary:logistic                100                      4              15   \n",
       "9   binary:logistic                200                      6              15   \n",
       "10  binary:logistic                200                      2               9   \n",
       "11  binary:logistic                200                      4               9   \n",
       "12  binary:logistic                200                      4               9   \n",
       "13  binary:logistic                150                      2               9   \n",
       "14  binary:logistic                100                      4              12   \n",
       "15  binary:logistic                150                      6              15   \n",
       "16  binary:logistic                100                      4              15   \n",
       "17  binary:logistic                200                      4              10   \n",
       "18  binary:logistic                150                      2              15   \n",
       "19  binary:logistic                150                      4              10   \n",
       "20  binary:logistic                100                      6              10   \n",
       "21  binary:logistic                200                      2              15   \n",
       "22  binary:logistic                200                      6              10   \n",
       "\n",
       "   param_learning_rate param_gamma  ...  \\\n",
       "0                 0.05           1  ...   \n",
       "1                 0.02         0.2  ...   \n",
       "2                  0.1         0.2  ...   \n",
       "3                 0.05         0.2  ...   \n",
       "4                 0.02           0  ...   \n",
       "5                 0.02         0.2  ...   \n",
       "6                  0.1           0  ...   \n",
       "7                  0.1           1  ...   \n",
       "8                 0.05           1  ...   \n",
       "9                  0.1           0  ...   \n",
       "10                0.02           1  ...   \n",
       "11                 0.1         0.2  ...   \n",
       "12                0.05         0.2  ...   \n",
       "13                0.02           1  ...   \n",
       "14                0.05         0.2  ...   \n",
       "15                 0.1         0.2  ...   \n",
       "16                0.02           0  ...   \n",
       "17                0.05           1  ...   \n",
       "18                0.05           0  ...   \n",
       "19                0.05         0.2  ...   \n",
       "20                0.02           0  ...   \n",
       "21                0.02           1  ...   \n",
       "22                0.05           1  ...   \n",
       "\n",
       "                                               params split0_test_score  \\\n",
       "0   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "1   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "2   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "3   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "4   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "5   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "6   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "7   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "8   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "9   {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "10  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "11  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "12  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "13  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "14  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "15  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "16  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "17  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "18  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "19  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "20  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "21  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "22  {'objective': 'binary:logistic', 'n_estimators...               0.0   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.000000         0.000000        0.000000                2   \n",
       "1            0.000000         0.000000        0.000000                2   \n",
       "2            0.000000         0.000000        0.000000                2   \n",
       "3            0.000000         0.000000        0.000000                2   \n",
       "4            0.000000         0.000000        0.000000                2   \n",
       "5            0.000000         0.000000        0.000000                2   \n",
       "6            0.000000         0.000000        0.000000                2   \n",
       "7            0.000000         0.000000        0.000000                2   \n",
       "8            0.000000         0.000000        0.000000                2   \n",
       "9            0.000000         0.000000        0.000000                2   \n",
       "10           0.000000         0.000000        0.000000                2   \n",
       "11           0.000000         0.000000        0.000000                2   \n",
       "12           0.000000         0.000000        0.000000                2   \n",
       "13           0.000000         0.000000        0.000000                2   \n",
       "14           0.000000         0.000000        0.000000                2   \n",
       "15           0.000000         0.000000        0.000000                2   \n",
       "16           0.000000         0.000000        0.000000                2   \n",
       "17           0.000000         0.000000        0.000000                2   \n",
       "18           0.228899         0.114421        0.114449                1   \n",
       "19           0.000000         0.000000        0.000000                2   \n",
       "20           0.000000         0.000000        0.000000                2   \n",
       "21           0.000000         0.000000        0.000000                2   \n",
       "22           0.000000         0.000000        0.000000                2   \n",
       "\n",
       "    split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "0             0.228899            0.499061          0.363980         0.135081  \n",
       "1             0.000000            0.000000          0.000000         0.000000  \n",
       "2             0.857856            0.836030          0.846943         0.010913  \n",
       "3             0.000000            0.000000          0.000000         0.000000  \n",
       "4             0.000000            0.000000          0.000000         0.000000  \n",
       "5             0.000000            0.000000          0.000000         0.000000  \n",
       "6             0.000000            0.000000          0.000000         0.000000  \n",
       "7             0.000000            0.223075          0.111538         0.111538  \n",
       "8             0.000000            0.000000          0.000000         0.000000  \n",
       "9             0.000000            0.386474          0.193237         0.193237  \n",
       "10            0.228899            0.499061          0.363980         0.135081  \n",
       "11            0.512089            0.669896          0.590992         0.078903  \n",
       "12            0.228899            0.546762          0.387830         0.158932  \n",
       "13            0.000000            0.000000          0.000000         0.000000  \n",
       "14            0.000000            0.000000          0.000000         0.000000  \n",
       "15            0.000000            0.223075          0.111538         0.111538  \n",
       "16            0.000000            0.000000          0.000000         0.000000  \n",
       "17            0.228899            0.499061          0.363980         0.135081  \n",
       "18            0.724657            0.740783          0.732720         0.008063  \n",
       "19            0.000000            0.223075          0.111538         0.111538  \n",
       "20            0.000000            0.000000          0.000000         0.000000  \n",
       "21            0.228899            0.499061          0.363980         0.135081  \n",
       "22            0.000000            0.000000          0.000000         0.000000  \n",
       "\n",
       "[23 rows x 21 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_PredictScorer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-7361fd0b9380>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '_PredictScorer' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in grid.scorer_:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
